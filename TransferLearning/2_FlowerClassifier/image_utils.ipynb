{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "# from torch import nn\n",
    "# from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# import copy\n",
    "import seaborn as sns\n",
    "\n",
    "import train_utils\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    '''\n",
    "    This function loads saved parameters and state from previously trained Neural Network.\n",
    "    Input: file name of checkpoint\n",
    "    Output: model, optimizer, device (GPU or CPU), loss criterion, and checkpoint dictionary with secondary information\n",
    "    '''\n",
    "    # Read from checkpoint.pth saved file\n",
    "    filename = checkpoint #f'checkpoint2_{model_name}.pth'\n",
    "    \n",
    "    # Deserialize 'pickled' file (reading saved checkpoint)\n",
    "    ### Tip: use map location to enable run on CPU model trained in GPU\n",
    "    checkpoint = torch.load(filename, map_location=lambda storage, loc: storage)\n",
    "    \n",
    "    # Initialize model, applying custom setup for each one\n",
    "    model, optimizer, criterion = train_utils.set_nn(checkpoint['class_to_idx'], checkpoint['model_name'])\n",
    "    \n",
    "    # load model and optimizer saved state data\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    return model, optimizer, criterion, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cat_to_name(cat_to_name_file='cat_to_name.json'):\n",
    "\n",
    "    with open(cat_to_name_file, 'r') as f:\n",
    "        cat_to_name = json.load(f)\n",
    "        \n",
    "    return cat_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array, as expected by Torch.Tensor.\n",
    "    '''\n",
    "    # resize to 256 pixel\n",
    "    image = Image.open(image_path).resize((256,256))\n",
    "\n",
    "    # Center crop to 224 pixel\n",
    "    width, height = image.size   # Get dimensions\n",
    "    final_size = 224\n",
    "\n",
    "    left = (width - final_size)/2\n",
    "    top = (height - final_size)/2\n",
    "    right = (width + final_size)/2\n",
    "    bottom = (height + final_size)/2\n",
    "\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    # Transform image into np.array\n",
    "    im = np.array(image)\n",
    "\n",
    "    # Normalize pixels from [0 - 255] to [0 - 1.0] float range\n",
    "    im = (im - im.min()) / (im.max() - im.min())\n",
    "\n",
    "    # Normalize as expected by pre-trained model\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    im = (im - mean ) / std\n",
    "    \n",
    "    # Transpose moving color channel from third (matplotlib) to first position (pytorch)\n",
    "    im = im.transpose((2, 0, 1)) # color, x, y\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None):\n",
    "    \"\"\"Transforms back from Tensor to Image format and display.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "        \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = (std * image) + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    # Remove spines/axis\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, device, cat_to_name, k=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    # Bring model to device (CPU or GPU, if available)\n",
    "    model.to(device)\n",
    "    # Make sure model is ready to be used for classifying/evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # Transform original image into numpy array, as expected by Torch.Tensor\n",
    "    processed_image = process_image(image_path)\n",
    "\n",
    "    # Load processed image as Tensor. Fix: cast input image as float\n",
    "    input_tensor = torch.tensor(processed_image).float()\n",
    "        \n",
    "    # Use GPU if available\n",
    "    input_tensor = input_tensor.to(device)   \n",
    "    \n",
    "#     # As recommended, convert input image to FloatTensor\n",
    "#     input_tensor = input_tensor.float()\n",
    "    \n",
    "    # Add expected batch information for a single image\n",
    "    input_tensor = input_tensor.unsqueeze_(0)\n",
    "\n",
    "    output = model.forward(input_tensor)\n",
    "\n",
    "    probabilities = torch.exp(output)\n",
    "    top_p, top_class = probabilities.topk(k, dim=1)\n",
    "\n",
    "    # unpack from Tensor back to simple list\n",
    "    top_class = top_class.squeeze().tolist()\n",
    "    top_p = top_p.squeeze().tolist()\n",
    "        \n",
    "    # Convert indices to actual classes\n",
    "    idx_to_class = {val: key for key,val in model.class_to_idx.items()}\n",
    "    \n",
    "    top_label = [idx_to_class[class_] for class_ in top_class]\n",
    "    top_name = [cat_to_name[label] for label in top_label]\n",
    "        \n",
    "    return top_p, top_label, top_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image along with the top 5 classes\n",
    "import seaborn as sns\n",
    "def display_result(image_path, model):\n",
    "    \n",
    "    fig, axes = plt.subplots(2,1, figsize=(5,8))\n",
    "    \n",
    "    # Set up title\n",
    "    flower_num = image_path.split('/')[2]\n",
    "    title = checkpoint['class_to_idx'].get(str(flower_num))\n",
    "        \n",
    "    # Plot flower\n",
    "    img = process_image(image_path)\n",
    "    axes[0].set_title(title)\n",
    "    imshow(img, ax=axes[0]);\n",
    "    \n",
    "    # Make prediction\n",
    "    probs, classes, names = predict(image_path, model)\n",
    "    \n",
    "    # Plot bar chart\n",
    "    sns.barplot(x=probs, y=names, ax=axes[1],color=sns.color_palette()[0])\n",
    "    plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
