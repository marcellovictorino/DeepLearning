{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the supporting script with the main steps used while training an Artificial Neural Network using the Transfer Learning approach on the pre-trained models made available by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from time import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='flowers', arch='vgg16'):\n",
    "    \"\"\"\n",
    "    data_dir: directory containing all images, following the classical train/valid/test subfolder structure recommend by PyTorch\\n\n",
    "    arch: specify the architecture of the pre-trained model that will be used for Transfer Learning. Defaults to 'vgg16'\\n\n",
    "    > Obs.: The Inception architecture requires the training image to have at least 299 pixel instead of the typical 224.\n",
    "    \"\"\"\n",
    "    # Define train/validation/test folder structure\n",
    "    train_dir = data_dir + '/train'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    test_dir = data_dir + '/test'\n",
    "    \n",
    "    # Normalize the means and std for all images to match Pre-trained network\n",
    "    \n",
    "    # Note: Inception architecture requires at least 299 pixels for final image instead of typical 224\n",
    "    train_transforms = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                          transforms.RandomResizedCrop(299 if arch.lower().startswith('inception') else 224), \n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) \n",
    "\n",
    "    test_transforms = transforms.Compose([transforms.Resize(320 if arch.lower().startswith('inception') else 255),\n",
    "                                          transforms.CenterCrop(299 if arch.lower().startswith('inception') else 224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) \n",
    "\n",
    "    # Load the datasets with ImageFolder and apply transforms\n",
    "    train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    valid_data = datasets.ImageFolder(valid_dir, transform=test_transforms)\n",
    "    test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "\n",
    "    # Define the dataloaders for train, validation, and test\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    # Save the ordered index sequence as interpreted by the model while training. Required to later convert back to the correct Class/Label\n",
    "    class_to_idx = train_data.class_to_idx\n",
    "    \n",
    "    return train_loader, valid_loader, test_loader, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, valid_loader, test_loader, class_to_idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate GPU use if available and requested\n",
    "def activate_gpu(gpu='GPU'):\n",
    "    \"\"\"Use GPU if available and requested by user. Defaults to use GPU if available.\"\"\"\n",
    "    if torch.cuda.is_available() and gpu.lower() == 'gpu':\n",
    "        print('Running on GPU')\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        print('Running on CPU')\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "# device = activate_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_trained(class_to_idx, arch='vgg16'):\n",
    "    \"\"\"Download and returns one of the available pre-trained models.\\n\n",
    "    + arch = architecture to be loaded based on user input\\n\n",
    "    + class_to_idx: dictionary resulting from function load_data()\\n\\n\n",
    "    \n",
    "    Return pre-trained model.\n",
    "    \"\"\"\n",
    "    # NOTE: for some reason, using dictionary did not work. Kept going through all elements.\n",
    "    if arch.lower() == 'vgg16':\n",
    "        model = models.vgg16(pretrained=True)\n",
    "    \n",
    "    if arch.lower() == 'vgg19':\n",
    "        model = models.vgg19(pretrained=True)\n",
    "        \n",
    "    if arch.lower() == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        \n",
    "    if arch.lower() == 'inception_v3':\n",
    "        model = models.inception_v3(pretrained=True)\n",
    "    \n",
    "    # Download and Load pre-trained model\n",
    "    try:\n",
    "        model.class_to_idx = class_to_idx\n",
    "        return model\n",
    "    except:\n",
    "        print(f'Selected architecture not recognized. Please, select one of: vgg16, vgg19, resnet50, or inception_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model = load_pre_trained()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nn(arch='vgg16', hidden_units=2048, dropout=0.5, lr=0.001):\n",
    "    \"\"\"Set up the Artificial Neural Network structure to implement Transfer Learning technique:\\n\n",
    "    1) Load pre-trained model,\\n\n",
    "    2) Freeze all but the last layer for training on images of interest,\\n\n",
    "    3) Define parameters of last layer based on specific architecture, using the number of hidden units based on user input\n",
    "    4) Define the Adam optimizer to be used for training the ANN, using the Learning Rate entered by user. Defaults to 0.001\\n\\n\n",
    "    \n",
    "    Returns the final model structure and optimizer based on user input.\n",
    "    \"\"\" \n",
    "    # Load pre-trained model\n",
    "    model = load_pre_trained(class_to_idx, arch)\n",
    "    \n",
    "    # Freeze parameters to not backpropagate through them\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Redefine last layer to train on images/classes of interest\n",
    "    if arch.lower().startswith('vgg'):\n",
    "        # Save the number of input faetures for future Loading from Checkpoint\n",
    "        model.input_features = model.classifier[0].in_features\n",
    "        \n",
    "        model.classifier = nn.Sequential(nn.Linear(model.input_features, hidden_units),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout), # probability to randomly drop out a hidden layer\n",
    "                                 nn.Linear(hidden_units, len(model.class_to_idx)),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        # Only train the classifier parameters\n",
    "        optimizer = torch.optim.Adam(model.classifier.parameters(), lr=lr)\n",
    "        \n",
    "    elif arch.lower().startswith('resnet'):\n",
    "        model.input_features = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Sequential(nn.Linear(model.input_features, len(model.class_to_idx)),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "        # Only train the classifier parameters\n",
    "        optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr)\n",
    "        \n",
    "    elif arch.lower().startswith('inception'):\n",
    "        model.input_features = model.fc.in_features\n",
    "        \n",
    "        model.fc = nn.Sequential(nn.Linear(model.input_features, len(model.class_to_idx)),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        # Requirements to use Inception_v3\n",
    "        model.aux_logits = False\n",
    "        \n",
    "        # Only train the classifier parameters\n",
    "        optimizer = torch.optim.Adam(model.fc.parameters(), lr=lr)\n",
    "    \n",
    "    # Define criteria to evaluate model loss\n",
    "    criterion = nn.NLLLoss() # Negative Log Likelihood Loss\n",
    "    \n",
    "    model.name = arch.lower() # Saves the architecture used for future reference\n",
    "    \n",
    "    return model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, optimizer, criterion = set_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, optimizer, criterion, train_loader, valid_loader, test_loader, device, epochs=5):\n",
    "    \"\"\"Trains the Artificial Neural Network, printing the training summary for each epoch and final results.\\n\n",
    "    A training log is saved as text file.\\n\n",
    "    + model: predefined model to trained\\n\n",
    "    + optimizer: predefined Adam optimizer\\n\n",
    "    + criterion: predefined loss criteria\\n\n",
    "    + train_loader: predefined loader with images to be used for training\\n\n",
    "    + valid_loader: predefined loader with images to be used for validation\\n\n",
    "    + test_loader: predefined loader with images to be used for testing\\n\n",
    "    + device: predefined state to use GPU if available\n",
    "    + epochs: number of epochs to perform training, defined by user input. Defaults to 5.\\n\\n\n",
    "    \n",
    "    Returns the best model based on validation accuracy.\n",
    "    \"\"\"\n",
    "    best_model = 0\n",
    "    best_score = 0\n",
    "\n",
    "    # Define Learning Rate Decay using scheduler - as recommended by PyTorch\n",
    "    ### Every step_size epochs, lr = lr * gamma\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    \n",
    "     # Use GPU if available\n",
    "    model = model.to(device)\n",
    "\n",
    "    start = time()\n",
    "    \n",
    "    with open(f'trainingLog_{model.name}.txt', 'w') as log:\n",
    "        for epoch in range(epochs):\n",
    "            # Training Stage\n",
    "            training_losses = []\n",
    "            validation_losses = []\n",
    "            running_loss = 0\n",
    "            model.train() #!Important: set train mode, applying dropout etc.\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "\n",
    "                # !Important: restart optimizer for every new batch\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # move input and label tensors to the appropriate device (GPU or CPU)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Perform forward pass to transform input into output\n",
    "                outputs = model.forward(inputs) # since last layer is LogSoftMax, output is Log\n",
    "\n",
    "                # Calculate error. Using Negative Log Loss instead of delta probability\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Back propagate\n",
    "                loss.backward()\n",
    "\n",
    "                # Calibrate Weights based on Gradient Descent\n",
    "                optimizer.step()\n",
    "\n",
    "                # Keep track of training progress\n",
    "                running_loss += loss.item()\n",
    "                training_losses.append(running_loss/len(train_loader))\n",
    "\n",
    "            # Validation Stage\n",
    "            validation_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval() #! Important: enter evaluation mode, no drop-out applied\n",
    "\n",
    "            with torch.no_grad(): # ! Important: no gradient descent on following calculations\n",
    "                for inputs, labels in valid_loader:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    predictions = model.forward(inputs)\n",
    "                    batch_loss = criterion(predictions, labels)\n",
    "                    validation_loss += batch_loss.item()\n",
    "\n",
    "                    validation_losses.append(validation_loss/len(valid_loader))\n",
    "\n",
    "                    # Calculate Accuracy\n",
    "                    probabilities = torch.exp(predictions) #proba = exp^(log)\n",
    "                    top_p, top_class = probabilities.topk(1, dim=1) # returns class with higher probability score\n",
    "\n",
    "                    equals = (top_class == labels.view(*top_class.shape)) # True (1) or False (0)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                    # Evaluate model performance and keep only the best\n",
    "                    if accuracy/len(valid_loader) > best_score:\n",
    "                        best_score = accuracy/len(valid_loader)\n",
    "                        best_model = copy.deepcopy(model)\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "            results_summary = (f'Epoch [{epoch+1}/{epochs}] '\n",
    "                               f'Learning Rate: {current_lr:.6f} | '\n",
    "                              f'Train Loss: {running_loss/len(train_loader) :.3f} | '\n",
    "                              f'Validation Loss: {validation_loss/len(valid_loader) :.3f} | '\n",
    "                              f'Validation Accuracy: {accuracy/len(valid_loader) :.2%} | '\n",
    "                              f'Time: {(time()-start):.0f} s\\n')\n",
    "            \n",
    "            # Print and save to log\n",
    "            print(results_summary)\n",
    "            log.write(results_summary)\n",
    "\n",
    "            # take a step on scheduler for learning rate decay\n",
    "            scheduler.step()\n",
    "\n",
    "        # Load best model identified during training/validation process\n",
    "        model = best_model\n",
    "        \n",
    "        best_model_result = f'\\n    --> Best Validation Accuracy: {best_score:.2%}\\n'\n",
    "        print(best_model_result)\n",
    "        log.write(best_model_result)\n",
    "        \n",
    "        ###############################################################################\n",
    "        # Testing\n",
    "        \n",
    "        test_section = '\\n########## TESTING ##########\\n'\n",
    "        print(test_section)\n",
    "        log.write(test_section)\n",
    "        \n",
    "        testing_accuracy = []\n",
    "\n",
    "        model.eval() #! Important: enter evaluation mode, no drop-out applied\n",
    "        start = time()\n",
    "\n",
    "        with torch.no_grad(): # ! Important: no gradient descent on following calculations\n",
    "            for inputs, labels in test_loader: \n",
    "                test_loss = 0\n",
    "                accuracy = 0 \n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model.forward(inputs)\n",
    "                batch_loss = criterion(outputs, labels)\n",
    "                test_loss += batch_loss.item()\n",
    "\n",
    "                # Calculate Accuracy\n",
    "                probabilities = torch.exp(outputs) #proba = exp^(log)\n",
    "                top_p, top_class = probabilities.topk(1, dim=1) # returns class with higher probability score\n",
    "\n",
    "                equals = (top_class == labels.view(*top_class.shape)) # True (1) or False (0)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                testing_accuracy.append(accuracy)\n",
    "                \n",
    "                test_result = f'Test Loss: {test_loss:.3f} | Test Accuracy: {accuracy:.2%} | Time: {(time()-start):.0f} sec'\n",
    "                print(test_result)\n",
    "                log.write(test_result)\n",
    "\n",
    "        test_summary = f'Overall average Test Accuracy: {sum(testing_accuracy)/len(testing_accuracy):.2%}\\n'\n",
    "        print(test_summary)\n",
    "        log.write(test_summary)  \n",
    "        \n",
    "        # Save hyperparameter info for future use\n",
    "        model.epochs = epochs\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-e81adc689cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-536e3c416ad8>\u001b[0m in \u001b[0;36mtrain_nn\u001b[0;34m(model, optimizer, criterion, train_loader, valid_loader, device, epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# Perform forward pass to transform input into output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# since last layer is LogSoftMax, output is Log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;31m# Calculate error. Using Negative Log Loss instead of delta probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = train_nn(model, optimizer, criterion, train_loader, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, save_dir='checkpoints'):\n",
    "    \"\"\"Save trained model as checkpoint file for later reference: `checkpoint_model_name.pth`\"\"\"\n",
    "    checkpoint = {'epochs': model.epochs,\n",
    "                  'model_name': model.name,\n",
    "                  'input': model.input_features,\n",
    "                  'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx}\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    torch.save(checkpoint, f'{save_dir}/checkpoint_{model.name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_checkpoint(model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
